#####################################################################
#####  configuration file to train the model to detect quarry  ##### 
#####################################################################
# Follow the workflow to train the model to detect quarries with a provided ground truth
# Refer to the README.md provided for more details


# 1-Prepare the tiles geometry according to the AOI and zoom level
prepare_data.py:  
  srs: "EPSG:2056"                                                # Projection of the input file
  datasets:
    labels_shapefile: ../input/input-trne/tlm-hr-trn-topo.shp     # Ground Truth 
  empty_tiles:
    enable: False                                                 # Enable adding random empty tiles to the dataset for model training
    tiles_frac: 0.5                                               # Proportion of empty tiles to add  
    border_shapefile: ../input/input-trne/switzerland_border.shp  # AOI for which additional empty tiles can be selected   
  output_folder: ../output/output-trne
  zoom_level: 16                                                  #z, keep between 15 and 18  

# 2-Request tiles according to the provided AOI and tiles parameters and split tiles into 3 datasets: train, test, validation
generate_tilesets.py:
  debug_mode: 
    enable: False                                                 # Enable to work on a subset of tiles 
    nb_tiles: 100
  empty_tiles:
    enable: False                                                 # Enable option to take into account empty tiles in the model training datasets  
    add_trn_frac: 1.0                                             # Proportion of empty tiles to add to the training dataset. The rest is split in half between test and validation datasets 
  datasets:
    aoi_tiles_geojson: ../output/output-trne/tiles.geojson
    ground_truth_labels_geojson: ../output/output-trne/labels.geojson
    orthophotos_web_service:
      type: XYZ                                                   # supported values: 1. MIL = Map Image Layer 2. WMS 3. XYZ
      url: https://wmts.geo.admin.ch/1.0.0/ch.swisstopo.swissimage-product/default/2020/3857/{z}/{x}/{y}.jpeg 
  output_folder: ../output/output-trne
  tile_size: 256                                                  # Size per side, in pixels
  overwrite: False
  n_jobs: 10
  COCO_metadata:
    year: 2021
    version: 1.0
    description: Swiss Image Hinterground w/ Quarry and exploitation site detection
    contributor: swisstopo
    url: https://swisstopo.ch
    license:
      name: Unknown
      url:
    category:
        name: "Quarry"
        supercategory: "Land usage"

# 3-Train the model with the detectron2 algorithm
# Monitor the training process via tensorboard (tensorboard --logdir </logs>). Choice of the optimized model: minimisation of the validation loss curve
train_model.py:
  working_folder: ../output/output-trne
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files: 
      trn: COCO_trn.json
      val: COCO_val.json
      tst: COCO_tst.json
  detectron2_config_file: '../../config/detectron2_config_dqry.yaml' 
  model_weights:
      model_zoo_checkpoint_url: "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml"

# 4-Perform the object detection based on the optimized trained model
make_predictions.py:
  working_folder: ../output/output-trne
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files:
      trn: COCO_trn.json
      val: COCO_val.json
      tst: COCO_tst.json
  detectron2_config_file: '../../config/detectron2_config_dqry.yaml'  
  model_weights:
      pth_file: './logs/model_0002999.pth'                            # !!!Chose the optimized trained model, i.e. the saved model iteration minimizing the validation loss curve  
  image_metadata_json: '../output/output-trne/img_metadata.json'
  rdp_simplification:                                                 # rdp = Ramer-Douglas-Peucker, shape geometry simplification algorithm
    enabled: true   
    epsilon: 0.5                                                      # smothing parameter, cf. https://rdp.readthedocs.io/en/latest/
  score_lower_threshold: 0.05                                         # filter prediction lower score 
    
# 5-Evaluate the quality of the prediction for the different datasets with metrics calculation
assess_predictions.py:
  datasets:
    ground_truth_labels_geojson: ../output/output-trne/labels.geojson
    image_metadata_json: ../output/output-trne/img_metadata.json
    split_aoi_tiles_geojson: ../output/output-trne/split_aoi_tiles.geojson # aoi = Area of Interest
    predictions:
      trn: ../output/output-trne/trn_predictions_at_0dot05_threshold.gpkg
      val: ../output/output-trne/val_predictions_at_0dot05_threshold.gpkg
      tst: ../output/output-trne/tst_predictions_at_0dot05_threshold.gpkg
  output_folder: ../output/output-trne

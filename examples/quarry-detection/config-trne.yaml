#############################################
####### Model training and evaluation ####### 
# Training of automatic detection of Quarries and Mineral Extraction Sites (MES) in images with a provided ground truth

# 1-Produce tiles geometry according to the AOI extent and zoom level
prepare_data.py:  
  srs: "EPSG:2056"
  datasets:
    labels_shapefile: ./data/labels/tlm-hr-trn-topo.shp
  output_folder: ./output/output-trne
  zoom_level: 16 

# 2-Fetch of tiles (online server) and split into 3 datasets: train, test, validation
generate_tilesets.py:
  debug_mode: False # sample of tiles
  datasets:
    aoi_tiles_geojson: ./output/output-trne/tiles.geojson
    ground_truth_labels_geojson: ./output/output-trne/labels.geojson
    orthophotos_web_service:
      type: XYZ # supported values: 1. MIL = Map Image Layer 2. WMS 3. XYZ
      url: https://wmts.geo.admin.ch/1.0.0/ch.swisstopo.swissimage-product/default/2020/3857/{z}/{x}/{y}.jpeg
  output_folder: ./output/output-trne
  tile_size: 256 # per side, in pixels
  overwrite: False
  n_jobs: 10
  COCO_metadata:
    year: 2021
    version: 1.0
    description: Swiss Image Hinterground w/ Quarries and Mineral Exploitation Sites detection
    contributor: swisstopo
    url: https://swisstopo.ch
    license:
      name: Unknown
      url:
    category:
      name: "Quarry"
      supercategory: "Land usage"

# 3-Train the model with the detectron2 algorithm
train_model.py:
  working_folder: ./output/output-trne
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files: # relative paths, w/ respect to the working_folder
    trn: COCO_trn.json
    val: COCO_val.json
    tst: COCO_tst.json
  detectron2_config_file: '../../detectron2_config_dqry.yaml' # path relative to the working_folder
  model_weights:
    model_zoo_checkpoint_url: "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml"

# 4-Perform the object detection based on the optimized trained model
make_predictions.py:
  working_folder: ./output/output-trne
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files: # relative paths, w/ respect to the working_folder
    trn: COCO_trn.json
    val: COCO_val.json
    tst: COCO_tst.json
  detectron2_config_file: '../../detectron2_config_dqry.yaml' # path relative to the working_folder
  model_weights:
    pth_file: './logs/model_0002999.pth' # trained model minimizing the validation loss curve, monitor the training process via tensorboard (tensorboard --logdir </logs>)
  image_metadata_json: './output/output-trne/img_metadata.json'
  rdp_simplification: # rdp = Ramer-Douglas-Peucker
    enabled: true
    epsilon: 2.0 # cf. https://rdp.readthedocs.io/en/latest/
  score_lower_threshold: 0.05
    
# 5-Evaluate the quality of the prediction for the different datasets with metrics calculation
assess_predictions.py:
  datasets:
    ground_truth_labels_geojson: ./output/output-trne/labels.geojson
    image_metadata_json: ./output/output-trne/img_metadata.json
    split_aoi_tiles_geojson: ./output/output-trne/split_aoi_tiles.geojson # aoi = Area of Interest
    predictions:
      trn: ./output/output-trne/trn_predictions_at_0dot05_threshold.gpkg
      val: ./output/output-trne/val_predictions_at_0dot05_threshold.gpkg
      tst: ./output/output-trne/tst_predictions_at_0dot05_threshold.gpkg
  output_folder: ./output/output-trne
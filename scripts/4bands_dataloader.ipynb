{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os, sys\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.visualizer import ColorMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers.misc import reformat_xyz, scale_polygon\n",
    "from helpers import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.detectron2 import LossEvalHook # , CocoTrainer\n",
    "from helpers.detectron2 import dt2predictions_to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare_data.py\n",
    "Making the labels right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROADS=\"/mnt/data-01/gsalamin/proj-roadsurf-b/02_Data/processed/shapefiles_gpkg/roads_polygons.shp\"\n",
    "TILES=\"/mnt/data-01/gsalamin/proj-roadsurf-b/02_Data/processed/json/tiles_aoi_z17.geojson\"\n",
    "\n",
    "OUTPUT_DIR=\"/mnt/data-01/gsalamin/proj-roadsurf-b/02_Data/processed/json\"\n",
    "\n",
    "written_files=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads=gpd.read_file(ROADS)\n",
    "tiles=gpd.read_file(TILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write a function valid_geom(poly_gdf, correct=False, gdf_obj_name=None)\n",
    "\n",
    "try:\n",
    "    assert(roads[roads.is_valid==False].shape[0]==0), \"Some geometries for the roads are invalid\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_gdf = roads.rename(columns={'BELAGSART': 'CATEGORY', 'road_width':'WIDTH'}).drop(columns=[\n",
    "                    'DATUM_AEND', 'DATUM_ERST', 'ERSTELLUNG', 'ERSTELLU_1',\n",
    "                    'REVISION_J', 'REVISION_M', 'GRUND_AEND', 'HERKUNFT', 'HERKUNFT_J',\n",
    "                    'HERKUNFT_M', 'REVISION_Q', 'WANDERWEGE', 'VERKEHRSBE', \n",
    "                    'BEFAHRBARK', 'EROEFFNUNG', 'STUFE', 'RICHTUNGSG', \n",
    "                    'KREISEL', 'EIGENTUEME', 'VERKEHRS_1', 'NAME',\n",
    "                    'TLM_STRASS', 'STRASSENNA', 'SHAPE_Leng',])\n",
    "labels_gdf['SUPERCATEGORY']='road'\n",
    "labels_gdf = labels_gdf.to_crs(epsg=4326)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert( labels_gdf.crs == tiles.crs ), f\"CRS mismatching: labels' CRS = {labels_gdf.crs} != OK_tiles' CRS = {tiles.crs}\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if labels_gdf[labels_gdf.is_valid==False].shape[0]!=0:\n",
    "    print(f\"There are {labels_gdf[labels_gdf.is_valid==False].shape[0]} invalid geometries for the reprojected labels.\")\n",
    "\n",
    "    print(\"Correction of the roads presenting an invalid geometry with a buffer of 0 m...\")\n",
    "    corrected_labels=labels_gdf.copy()\n",
    "    corrected_labels.loc[corrected_labels.is_valid==False,'geometry']=corrected_labels[corrected_labels.is_valid==False]['geometry'].buffer(0)\n",
    "    labels_gdf=corrected_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_labels_gdf = gpd.sjoin(labels_gdf, tiles, how='inner', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the following two lines make sure that no object is counted more than once in case it intersects multiple tiles\n",
    "GT_labels_gdf = GT_labels_gdf[labels_gdf.columns]\n",
    "GT_labels_gdf.drop_duplicates(inplace=True)\n",
    "OTH_labels_gdf = labels_gdf[ ~labels_gdf.index.isin(GT_labels_gdf.index)]\n",
    "\n",
    "# In the current case, OTH_labels_gdf should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert( len(labels_gdf) == len(GT_labels_gdf) + len(OTH_labels_gdf) ),\\\n",
    "        f\"Something went wrong when splitting labels into Ground Truth Labels and Other Labels. Total no. of labels = {len(labels_gdf)}; no. of Ground Truth Labels = {len(GT_labels_gdf)}; no. of Other Labels = {len(OTH_labels_gdf)}\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_LABELS_GEOJSON = os.path.join(OUTPUT_DIR, f'ground_truth_labels.geojson')\n",
    "OTH_LABELS_GEOJSON = os.path.join(OUTPUT_DIR, f'other_labels.geojson')\n",
    "\n",
    "GT_labels_gdf.to_file(GT_LABELS_GEOJSON, driver='GeoJSON')\n",
    "written_files.append(GT_LABELS_GEOJSON)\n",
    "\n",
    "if not OTH_labels_gdf.empty:\n",
    "    OTH_labels_gdf.to_file(OTH_LABELS_GEOJSON, driver='GeoJSON')\n",
    "    written_files.append(OTH_LABELS_GEOJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_labels_gdf[GT_labels_gdf.is_valid==False]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate_tilesets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_to_bbox(bounds):\n",
    "    \n",
    "    xmin = bounds[0]\n",
    "    ymin = bounds[1]\n",
    "    xmax = bounds[2]\n",
    "    ymax = bounds[3]\n",
    "    \n",
    "    bbox = f\"{xmin},{ymin},{xmax},{ymax}\"\n",
    "    \n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_COCO_image_and_segmentations(tile, labels, COCO_license_id, output_dir):\n",
    "    \n",
    "    _id, _tile = tile\n",
    "\n",
    "    coco_obj = COCO.COCO()\n",
    "\n",
    "    this_tile_dirname = os.path.relpath(_tile['img_file'].replace('all', _tile['dataset']), output_dir)\n",
    "    this_tile_dirname = this_tile_dirname.replace('\\\\', '/') # should the dirname be generated from Windows\n",
    "\n",
    "    COCO_image = coco_obj.image(output_dir, this_tile_dirname, COCO_license_id)\n",
    "    segmentations = []\n",
    "    \n",
    "    if len(labels) > 0:\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = [float(x) for x in bounds_to_bbox(_tile['geometry'].bounds).split(',')]\n",
    "        \n",
    "        # note the .explode() which turns Multipolygon into Polygons\n",
    "        clipped_labels_gdf = gpd.clip(labels, _tile['geometry']).explode()\n",
    "\n",
    "        #try:\n",
    "        #    assert( len(clipped_labels_gdf) > 0 ) \n",
    "        #except:\n",
    "        #    raise Exception(f'No labels found within this tile! Tile ID = {tile.id}')  \n",
    "\n",
    "        for label in clipped_labels_gdf.itertuples():\n",
    "            scaled_poly = scale_polygon(label.geometry, xmin, ymin, xmax, ymax, \n",
    "                                             COCO_image['width'], COCO_image['height'])\n",
    "            scaled_poly = scaled_poly[:-1] # let's remove the last point\n",
    "\n",
    "            segmentation = my_unpack(scaled_poly)\n",
    "\n",
    "            try:\n",
    "                assert(min(segmentation) >= 0)\n",
    "                assert(max(segmentation) <= min(COCO_image['width'], COCO_image['height']))\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Label boundaries exceed this tile size! Tile ID = {_tile['id']}\")\n",
    "                \n",
    "            segmentations.append(segmentation)\n",
    "            \n",
    "    return (COCO_image, segmentations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hard_link(row):\n",
    "\n",
    "    if not os.path.isfile(row.img_file):\n",
    "        raise Exception('File not found.')\n",
    "\n",
    "    src_file = row.img_file\n",
    "    dst_file = src_file.replace('all', row.dataset)\n",
    "\n",
    "    dirname = os.path.dirname(dst_file)\n",
    "\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "    if os.path.exists(dst_file):\n",
    "        os.remove(dst_file)\n",
    "\n",
    "    os.link(src_file, dst_file)\n",
    "\n",
    "    return None\n",
    "\n",
    "def img_md_record_to_tile_id(img_md_record):\n",
    "    \n",
    "    filename = os.path.split(img_md_record.img_file)[-1]\n",
    "    \n",
    "    z_x_y = filename.split('.')[0]\n",
    "    z, x, y = z_x_y.split('_')\n",
    "    \n",
    "    return f\"({x}, {y}, {z})\"\n",
    "\n",
    "def check_aoi_tiles(aoi_tiles_gdf):\n",
    "    '''\n",
    "    Check that the id of the AoI tile is exists and will be accepted by the function reformat_xyz\n",
    "    The format should be \"(<x>, <y>, <z>)\" or \"<x>, <y>, <z>\"\n",
    "    '''\n",
    "    \n",
    "    if 'id' not in aoi_tiles_gdf.columns.to_list():\n",
    "        raise Exception(\"No 'id' column was found in the AoI tiles dataset.\")\n",
    "    if len(aoi_tiles_gdf[aoi_tiles_gdf.id.duplicated()]) > 0:\n",
    "        raise Exception(\"The 'id' column in the AoI tiles dataset should not contain any duplicate.\")\n",
    "    \n",
    "    try:\n",
    "        aoi_tiles_gdf.apply(reformat_xyz, axis=1)\n",
    "    except:\n",
    "        raise Exception(\"IDs do not seem to be well-formatted. Here's how they must look like: (<integer 1>, <integer 2>, <integer 3>), e.g. (<x>, <y>, <z>).\")\n",
    "    \n",
    "    if not aoi_tiles_gdf['id'].str.startswith('(').all():\n",
    "        aoi_tiles_gdf['id']='('+aoi_tiles_gdf['id']\n",
    "    if not aoi_tiles_gdf['id'].str.endswith(')').all():\n",
    "        aoi_tiles_gdf['id']=aoi_tiles_gdf['id']+')'\n",
    "    \n",
    "    return\n",
    "\n",
    "def my_unpack(list_of_tuples):\n",
    "    # cf. https://www.geeksforgeeks.org/python-convert-list-of-tuples-into-list/\n",
    "    \n",
    "    return [item for t in list_of_tuples for item in t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/gsalamin/Documents/GitHub/object-detector/scripts/config_test_NIR.yaml\") as fp:\n",
    "        cfg = yaml.load(fp, Loader=yaml.FullLoader)[\"generate_tilesets.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_MODE = cfg['debug_mode']\n",
    "\n",
    "OUTPUT_DIR = cfg['output_folder']\n",
    "\n",
    "ORTHO_WS_TYPE = cfg['datasets']['orthophotos_web_service']['type']\n",
    "ORTHO_WS_URL = cfg['datasets']['orthophotos_web_service']['url']\n",
    "ORTHO_WS_SRS = cfg['datasets']['orthophotos_web_service']['srs']\n",
    "if 'layers' in cfg['datasets']['orthophotos_web_service'].keys():\n",
    "    ORTHO_WS_LAYERS = cfg['datasets']['orthophotos_web_service']['layers']\n",
    "\n",
    "AOI_TILES_GEOJSON = cfg['datasets']['aoi_tiles_geojson']\n",
    "\n",
    "if 'ground_truth_labels_geojson' in cfg['datasets'].keys():\n",
    "    GT_LABELS_GEOJSON = cfg['datasets']['ground_truth_labels_geojson']\n",
    "else:\n",
    "    GT_LABELS_GEOJSON = None\n",
    "if 'other_labels_geojson' in cfg['datasets'].keys():\n",
    "    OTH_LABELS_GEOJSON = cfg['datasets']['other_labels_geojson']\n",
    "else:\n",
    "    OTH_LABELS_GEOJSON = None\n",
    "\n",
    "SAVE_METADATA = True\n",
    "OVERWRITE = cfg['overwrite']\n",
    "TILE_SIZE = cfg['tile_size']\n",
    "N_JOBS = cfg['n_jobs']\n",
    "COCO_YEAR = cfg['COCO_metadata']['year']\n",
    "COCO_VERSION = cfg['COCO_metadata']['version']\n",
    "COCO_DESCRIPTION = cfg['COCO_metadata']['description']\n",
    "COCO_CONTRIBUTOR = cfg['COCO_metadata']['contributor']\n",
    "COCO_URL = cfg['COCO_metadata']['url']\n",
    "COCO_LICENSE_NAME = cfg['COCO_metadata']['license']['name']\n",
    "COCO_LICENSE_URL = cfg['COCO_metadata']['license']['url']\n",
    "COCO_CATEGORY_NAME = cfg['COCO_metadata']['category']['name']\n",
    "COCO_CATEGORY_SUPERCATEGORY = cfg['COCO_metadata']['category']['supercategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GT_LABELS_GEOJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make the output directory in case it doesn't exist\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "written_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Loading datasets\n",
    "\n",
    "aoi_tiles_gdf = gpd.read_file(AOI_TILES_GEOJSON)\n",
    "try:\n",
    "    check_aoi_tiles(aoi_tiles_gdf)\n",
    "except Exception as e:\n",
    "    print(f\"AoI tiles check failed. Exception: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if GT_LABELS_GEOJSON:\n",
    "    print(\"Loading Ground Truth Labels as a GeoPandas DataFrame...\")\n",
    "    gt_labels_gdf = gpd.read_file(GT_LABELS_GEOJSON)\n",
    "    print(f\"...done. {len(gt_labels_gdf)} records were found.\")\n",
    "\n",
    "    try:\n",
    "        assert(gt_labels_gdf[gt_labels_gdf.is_valid==False].shape[0]==0), \"Some geometries for the ground truth labels are invalid.\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        corrected_labels=gt_labels_gdf.copy()\n",
    "        corrected_labels.loc[corrected_labels.is_valid==False,'geometry']=corrected_labels[corrected_labels.is_valid==False]['geometry'].buffer(0)\n",
    "        gt_labels_gdf=corrected_labels.copy()\n",
    "\n",
    "if OTH_LABELS_GEOJSON:\n",
    "    print(\"Loading Other Labels as a GeoPandas DataFrame...\")\n",
    "    oth_labels_gdf = gpd.read_file(OTH_LABELS_GEOJSON)\n",
    "    print(f\"...done. {len(oth_labels_gdf)} records were found.\")\n",
    "\n",
    "    try:\n",
    "        assert(oth_labels_gdf[oth_labels_gdf.is_valid==False].shape[0]==0), \"Some geometries for the other labels are invalid.\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "            \n",
    "\n",
    "print(\"Generating the list of tasks to be executed (one task per tile)...\")\n",
    "\n",
    "DEBUG_MODE_LIMIT = 100\n",
    "if DEBUG_MODE:\n",
    "    print(f\"Debug mode: ON => Only {DEBUG_MODE_LIMIT} tiles will be processed.\")\n",
    "\n",
    "    if GT_LABELS_GEOJSON:\n",
    "        assert( aoi_tiles_gdf.crs == gt_labels_gdf.crs )\n",
    "        aoi_tiles_intersecting_gt_labels = gpd.sjoin(aoi_tiles_gdf, gt_labels_gdf, how='inner', op='intersects')\n",
    "        aoi_tiles_intersecting_gt_labels = aoi_tiles_intersecting_gt_labels[aoi_tiles_gdf.columns]\n",
    "        aoi_tiles_intersecting_gt_labels.drop_duplicates(inplace=True)\n",
    "\n",
    "    if OTH_LABELS_GEOJSON:\n",
    "        assert( aoi_tiles_gdf.crs == oth_labels_gdf.crs )\n",
    "        aoi_tiles_intersecting_oth_labels = gpd.sjoin(aoi_tiles_gdf, oth_labels_gdf, how='inner', op='intersects')\n",
    "        aoi_tiles_intersecting_oth_labels = aoi_tiles_intersecting_oth_labels[aoi_tiles_gdf.columns]\n",
    "        aoi_tiles_intersecting_oth_labels.drop_duplicates(inplace=True)\n",
    "        \n",
    "    # sampling tiles according to whether GT and/or GT labels are provided\n",
    "    if GT_LABELS_GEOJSON and OTH_LABELS_GEOJSON:\n",
    "\n",
    "        aoi_tiles_gdf = pd.concat([\n",
    "            aoi_tiles_intersecting_gt_labels.head(DEBUG_MODE_LIMIT//2), # a sample of tiles covering GT labels\n",
    "            aoi_tiles_intersecting_oth_labels.head(DEBUG_MODE_LIMIT//4), # a sample of tiles convering OTH labels\n",
    "            aoi_tiles_gdf # the entire tileset, so as to also have tiles covering no label at all (duplicates will be dropped)\n",
    "        ])\n",
    "        \n",
    "    elif GT_LABELS_GEOJSON and not OTH_LABELS_GEOJSON:\n",
    "        aoi_tiles_gdf = pd.concat([\n",
    "            aoi_tiles_intersecting_gt_labels.head(DEBUG_MODE_LIMIT*3//4),\n",
    "            aoi_tiles_gdf\n",
    "        ])\n",
    "    \n",
    "    elif not GT_LABELS_GEOJSON and OTH_LABELS_GEOJSON:\n",
    "        aoi_tiles_gdf = pd.concat([\n",
    "            aoi_tiles_intersecting_oth_labels.head(DEBUG_MODE_LIMIT*3//4),\n",
    "            aoi_tiles_gdf\n",
    "        ])\n",
    "    else:\n",
    "        pass # the following two lines of code would apply in this case\n",
    "        \n",
    "    aoi_tiles_gdf.drop_duplicates(inplace=True)\n",
    "    aoi_tiles_gdf = aoi_tiles_gdf.head(DEBUG_MODE_LIMIT).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels_gdf[gt_labels_gdf.is_valid==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert( aoi_tiles_gdf.crs == gt_labels_gdf.crs ), \"CRS Mismatch between AoI tiles and labels.\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "\n",
    "GT_tiles_gdf = gpd.sjoin(aoi_tiles_gdf, gt_labels_gdf, how='inner', op='intersects')\n",
    "# remove columns generated by the Spatial Join\n",
    "GT_tiles_gdf = GT_tiles_gdf[aoi_tiles_gdf.columns].copy()\n",
    "GT_tiles_gdf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tiles including at least one \"oth\" label (if applicable)\n",
    "if OTH_LABELS_GEOJSON:\n",
    "    tmp_GT_tiles_gdf = GT_tiles_gdf.copy()\n",
    "    tiles_to_remove_gdf = gpd.sjoin(tmp_GT_tiles_gdf, oth_labels_gdf, how='inner', op='intersects')\n",
    "    GT_tiles_gdf = tmp_GT_tiles_gdf[~tmp_GT_tiles_gdf.id.astype(str).isin(tiles_to_remove_gdf.id.astype(str))].copy()\n",
    "    del tmp_GT_tiles_gdf\n",
    "\n",
    "# OTH tiles = AoI tiles which are not GT\n",
    "OTH_tiles_gdf = aoi_tiles_gdf[ ~aoi_tiles_gdf.id.astype(str).isin(GT_tiles_gdf.id.astype(str)) ].copy()\n",
    "OTH_tiles_gdf['dataset'] = 'oth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( len(aoi_tiles_gdf) == len(GT_tiles_gdf) + len(OTH_tiles_gdf) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70%, 15%, 15% split\n",
    "trn_tiles_ids = GT_tiles_gdf\\\n",
    "    .sample(frac=.7, random_state=1)\\\n",
    "    .id.astype(str).values.tolist()\n",
    "\n",
    "val_tiles_ids = GT_tiles_gdf[~GT_tiles_gdf.id.astype(str).isin(trn_tiles_ids)]\\\n",
    "    .sample(frac=.5, random_state=1)\\\n",
    "    .id.astype(str).values.tolist()\n",
    "\n",
    "tst_tiles_ids = GT_tiles_gdf[~GT_tiles_gdf.id.astype(str).isin(trn_tiles_ids + val_tiles_ids)]\\\n",
    "    .id.astype(str).values.tolist()\n",
    "\n",
    "GT_tiles_gdf.loc[GT_tiles_gdf.id.astype(str).isin(trn_tiles_ids), 'dataset'] = 'trn'\n",
    "GT_tiles_gdf.loc[GT_tiles_gdf.id.astype(str).isin(val_tiles_ids), 'dataset'] = 'val'\n",
    "GT_tiles_gdf.loc[GT_tiles_gdf.id.astype(str).isin(tst_tiles_ids), 'dataset'] = 'tst'\n",
    "\n",
    "assert( len(GT_tiles_gdf) == len(trn_tiles_ids) + len(val_tiles_ids) + len(tst_tiles_ids) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_aoi_tiles_gdf = pd.concat(\n",
    "    [\n",
    "        GT_tiles_gdf,\n",
    "        OTH_tiles_gdf\n",
    "    ]\n",
    ")\n",
    "\n",
    "# let's free up some memory\n",
    "del GT_tiles_gdf\n",
    "del OTH_tiles_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( len(split_aoi_tiles_gdf) == len(aoi_tiles_gdf) ) # it means that all the tiles were actually used\n",
    "\n",
    "SPLIT_AOI_TILES_GEOJSON = os.path.join(OUTPUT_DIR, 'split_aoi_tiles.geojson')\n",
    "\n",
    "try:\n",
    "    split_aoi_tiles_gdf.to_file(SPLIT_AOI_TILES_GEOJSON, driver='GeoJSON')\n",
    "    # sp_tiles_gdf.to_crs(epsg=2056).to_file(os.path.join(OUTPUT_DIR, 'swimmingpool_tiles.shp'))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "written_files.append(SPLIT_AOI_TILES_GEOJSON)\n",
    "print(f'...done. A file was written {SPLIT_AOI_TILES_GEOJSON}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_METADATA_FILE = os.path.join(OUTPUT_DIR, 'img_metadata.json')\n",
    "\n",
    "with open(IMG_METADATA_FILE) as f:\n",
    "    img_metadata_dict=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_md_df = pd.DataFrame.from_dict(img_metadata_dict, orient='index')\n",
    "img_md_df.reset_index(inplace=True)\n",
    "img_md_df.rename(columns={\"index\": \"img_file\"}, inplace=True)\n",
    "\n",
    "img_md_df['id'] = img_md_df.apply(img_md_record_to_tile_id, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "split_aoi_tiles_with_img_md_gdf = split_aoi_tiles_gdf.merge(img_md_df, on='id', how='left')\n",
    "split_aoi_tiles_with_img_md_gdf.apply(make_hard_link, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_gdf = gt_labels_gdf.copy().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the COCO annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in split_aoi_tiles_with_img_md_gdf.dataset.unique():\n",
    "    \n",
    "    coco = COCO.COCO()\n",
    "    coco.set_info(the_year=COCO_YEAR, \n",
    "                    the_version=COCO_VERSION, \n",
    "                    the_description=f\"{COCO_DESCRIPTION} - {dataset} dataset\", \n",
    "                    the_contributor=COCO_CONTRIBUTOR, \n",
    "                    the_url=COCO_URL)\n",
    "    \n",
    "    coco_license = coco.license(the_name=COCO_LICENSE_NAME, the_url=COCO_LICENSE_URL)\n",
    "    coco_license_id = coco.insert_license(coco_license)\n",
    "\n",
    "    # TODO: read (super)category from the labels datataset\n",
    "    coco_category = coco.category(the_name=COCO_CATEGORY_NAME, the_supercategory=COCO_CATEGORY_SUPERCATEGORY)                      \n",
    "    coco_category_id = coco.insert_category(coco_category)\n",
    "    \n",
    "    tmp_tiles_gdf = split_aoi_tiles_with_img_md_gdf[split_aoi_tiles_with_img_md_gdf.dataset == dataset].dropna()\n",
    "    #tmp_tiles_gdf = tmp_tiles_gdf.to_crs(epsg=3857)\n",
    "    \n",
    "    if len(labels_gdf) > 0:\n",
    "        assert(labels_gdf.crs == tmp_tiles_gdf.crs)\n",
    "    \n",
    "    tiles_iterator = tmp_tiles_gdf.sort_index().iterrows()\n",
    "\n",
    "    results = Parallel(n_jobs=N_JOBS, backend=\"loky\") \\\n",
    "                    (delayed(get_COCO_image_and_segmentations) \\\n",
    "                    (tile, labels_gdf, coco_license_id, OUTPUT_DIR) \\\n",
    "                    for tile in tqdm( tiles_iterator, total=len(tmp_tiles_gdf) ))\n",
    "    \n",
    "    for result in results:\n",
    "        coco_image, segmentations = result\n",
    "        coco_image_id = coco.insert_image(coco_image)\n",
    "\n",
    "        for segmentation in segmentations:\n",
    "\n",
    "            coco_annotation = coco.annotation(coco_image_id,\n",
    "                coco_category_id,\n",
    "                [segmentation],\n",
    "                the_iscrowd=0\n",
    "            )\n",
    "\n",
    "            coco.insert_annotation(coco_annotation)\n",
    "    \n",
    "    COCO_file = os.path.join(OUTPUT_DIR, f'COCO_{dataset}.json')\n",
    "    with open(COCO_file, 'w') as fp:\n",
    "        json.dump(coco.to_json(), fp)\n",
    "    written_files.append(COCO_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The following files were written. Let's check them out!\")\n",
    "for written_file in written_files:\n",
    "    print(written_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from detectron2.engine.hooks import HookBase\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader, DatasetMapper\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "# from detectron2.utils import comm\n",
    "# from detectron2.utils.logger import log_every_n_seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_ZOO_CHECKPOINT_URL = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"\n",
    "\n",
    "MODEL_PTH_FILE = None\n",
    "    \n",
    "COCO_TRN_FILE = \"COCO_trn.json\"\n",
    "COCO_VAL_FILE = \"COCO_val.json\"\n",
    "COCO_TST_FILE = \"COCO_tst.json\"\n",
    "        \n",
    "DETECTRON2_CFG_FILE = '/home/gsalamin/Documents/GitHub/object-detector/scripts/det2_config_test_NIR.yaml'\n",
    "\n",
    "WORKING_DIR = \"/mnt/data-01/gsalamin/proj-roadsurf-b/02_Data/processed/obj_detector\"\n",
    "SAMPLE_TAGGED_IMG_SUBDIR = \"sample_training_images\"\n",
    "LOG_SUBDIR = \"logs\"\n",
    "OUTPUT_DIR=WORKING_DIR+'/tests'   \n",
    "\n",
    "os.chdir(WORKING_DIR)\n",
    "# let's make the output directories in case they don't exist\n",
    "for DIR in [SAMPLE_TAGGED_IMG_SUBDIR, LOG_SUBDIR]:\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "\n",
    "written_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- register datasets\n",
    "register_coco_instances(\"trn_dataset\", {}, COCO_TRN_FILE, \"\")\n",
    "register_coco_instances(\"val_dataset\", {}, COCO_VAL_FILE, \"\")\n",
    "register_coco_instances(\"tst_dataset\", {}, COCO_TST_FILE, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "registered_datasets = ['trn_dataset', 'val_dataset', 'tst_dataset']\n",
    "    \n",
    "registered_datasets_prefixes = [x.split('_')[0] for x in registered_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in registered_datasets:\n",
    "    \n",
    "    for d in DatasetCatalog.get(dataset)[0:min(len(DatasetCatalog.get(dataset)), 4)]:\n",
    "        output_filename = \"tagged_\" + d[\"file_name\"].split('/')[-1]\n",
    "        output_filename = output_filename.replace('tif', 'png')\n",
    "        \n",
    "        img = cv2.imread(d[\"file_name\"])  \n",
    "        \n",
    "        visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(dataset), scale=1.0)\n",
    "        \n",
    "        vis = visualizer.draw_dataset_dict(d)\n",
    "        cv2.imwrite(os.path.join(SAMPLE_TAGGED_IMG_SUBDIR, output_filename), vis.get_image()[:, :, ::-1])\n",
    "        written_files.append( os.path.join(WORKING_DIR, os.path.join(SAMPLE_TAGGED_IMG_SUBDIR, output_filename)) )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The following files were written. Let's check them out!\")\n",
    "for written_file in written_files:\n",
    "    print(written_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf. https://detectron2.readthedocs.io/modules/config.html#config-references\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(DETECTRON2_CFG_FILE)\n",
    "cfg.OUTPUT_DIR = LOG_SUBDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(MODEL_ZOO_CHECKPOINT_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "    '''\n",
    "    Adding an evaluator for the test set, because it is not included by default\n",
    "    '''\n",
    "      \n",
    "    if output_folder is None:\n",
    "        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        \n",
    "    os.makedirs(\"COCO_eval\", exist_ok=True)\n",
    "    \n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "  @classmethod\n",
    "  def build_train_loader(cls, cfg):\n",
    "    '''\n",
    "    Build a custom dataloader to handel images with more than 3 channels\n",
    "    cf. https://detectron2.readthedocs.io/en/latest/tutorials/data_loading.html\n",
    "    '''\n",
    "\n",
    "    standard_formats=['1', 'L', 'P', 'RGB', 'RGBA']\n",
    "\n",
    "    if False: # cfg.INPUT.FORMAT==\"RGBNir\":\n",
    "      # TODO: modify the code from: https://detectron2.readthedocs.io/en/latest/_modules/detectron2/data/detection_utils.html#read_image\n",
    "      mapper=True # Get the custom mapper\n",
    "      print('This is a test')\n",
    "      sys.exit(1)\n",
    "    else:\n",
    "      mapper=DatasetMapper(cfg, is_train=True) # Default choice for mapper\n",
    "\n",
    "    return build_detection_train_loader(cfg, mapper=mapper)\n",
    "\n",
    "  \n",
    "  def build_hooks(self):\n",
    "    '''\n",
    "    A Hook is a function called on each step.\n",
    "    1- Add a custom Hook to the Trainer that gets called after EVAL_PERIOD steps\n",
    "    2- When the Hook is called, do inference on the whole Evaluation dataset\n",
    "    3- Every time inference is done, get the loss on the same way it is done when training, and store the mean value for all the dataset.\n",
    "    '''\n",
    "        \n",
    "    hooks = super().build_hooks()\n",
    "    \n",
    "    hooks.insert(-1,\n",
    "        LossEvalHook(\n",
    "            self.cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            build_detection_test_loader(self.cfg, self.cfg.DATASETS.TEST[0], DatasetMapper(self.cfg, True))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('test')\n",
    "                \n",
    "    return hooks\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CocoTrainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "# Test if the cell works without the print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('objdet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdeda2ddb1933d8968c8a69a320c7385bec9537628cd45580171e6df24fec89d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHnVupBBn9eR"
   },
   "source": [
    "# Swimming Pool Detection (STDL) running on FHNW HPC\n",
    "## Version 2021-01-13\n",
    "Model using combined Data of Geneva and Neuchatel\n",
    "Datasets were formatted into standardized COCO and merged with datumaro\n",
    "\n",
    "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJeQGhbueDeA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM54r6jlKTII"
   },
   "source": [
    "# Install dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qla8psAF9z1_",
    "outputId": "40f0289a-15c8-4d83-c712-be6f8b4ed010"
   },
   "outputs": [],
   "source": [
    "# install dependencies: \n",
    "!pip install pyyaml==5.1\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available(), torch.cuda.get_device_name(0))\n",
    "!gcc --version\n",
    "# opencv is pre-installed on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HV-MCV0t93QU",
    "outputId": "8f0e52e4-9838-4d9b-aa60-df7aa3cb4ae3"
   },
   "outputs": [],
   "source": [
    "# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "import torch\n",
    "assert torch.__version__.startswith(\"1.5\")\n",
    "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
    "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZyAvNCJMmvFF"
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AW2LKtP0u7uf"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2bjrfb2LDeo"
   },
   "source": [
    "# Train on a custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Lltu_mX2Xcl",
    "outputId": "b006d12e-b857-4d1a-b845-d0715cc86e92"
   },
   "outputs": [],
   "source": [
    "#Change to Directory with combined dataset\n",
    "os.chdir(\"../output-comb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNW0vZ8L-sSZ"
   },
   "outputs": [],
   "source": [
    "#! rm -rf {trn,tst,val}-images-256 && tar xfvz /content/drive/My\\ Drive/DeepLearning/SwimmingPoolDetection_NE/1/images-256.tar.gz > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjbUIhSxUdm_"
   },
   "source": [
    "\n",
    "## Fetch the dataset from Google Drive and unpack it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6kxqsMl8pER",
    "outputId": "6927172a-f929-43f6-9c98-b20d49c909c4"
   },
   "outputs": [],
   "source": [
    "! ls trn-images-256 | wc -l\n",
    "! ls val-images-256 | wc -l\n",
    "! ls tst-images-256 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVJoOm6LVJwW"
   },
   "source": [
    "Register the swimming pool dataset to Detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-9cYJY55tw6"
   },
   "outputs": [],
   "source": [
    "COCO_TRN_FILE = \"instances_trn.json\"\n",
    "COCO_VAL_FILE = \"instances_val.json\"\n",
    "COCO_TST_FILE = \"instances_tst.json\"\n",
    "\n",
    "# with open(COCO_TRN_FILE, 'r') as fp:\n",
    "#   coco_trn_dict = json.load(fp)\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"swimmingpool_trn_dataset\", {}, COCO_TRN_FILE, \"\")\n",
    "register_coco_instances(\"swimmingpool_val_dataset\", {}, COCO_VAL_FILE, \"\")\n",
    "register_coco_instances(\"swimmingpool_tst_dataset\", {}, COCO_TST_FILE, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zAXO9nay8I4g",
    "outputId": "52c565b8-c477-4056-e238-770024351878"
   },
   "outputs": [],
   "source": [
    "# let's check that everything's fine\n",
    "#DatasetCatalog.get(\"swimmingpool_trn_dataset\")[0]\n",
    "MetadataCatalog.get(\"swimmingpool_trn_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ljbWTX0Wi8E"
   },
   "source": [
    "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5AmdADcIADA3",
    "outputId": "5941d902-1ce9-45fd-b4e8-d898ec2812ad"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for d in random.sample(DatasetCatalog.get(\"swimmingpool_trn_dataset\"), 4):\n",
    "    print(d[\"file_name\"])\n",
    "    output_filename = \"tagged_\" + d[\"file_name\"].split('/')[-1]\n",
    "    output_filename = output_filename.replace('tif', 'png')\n",
    "    print(output_filename)\n",
    "    img = cv2.imread(d[\"file_name\"])  \n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(\"swimmingpool_trn_dataset\"), scale=1.0)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(vis.get_image()[:, :, :])\n",
    "    cv2.imwrite(output_filename, vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEeyKGYIRSfm"
   },
   "source": [
    "...as well as randomly selected samples in the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "id": "I6pKHVBhSuLe",
    "outputId": "3ca578f1-441e-4061-d20f-4a66e8c0ae13"
   },
   "outputs": [],
   "source": [
    "for d in random.sample(DatasetCatalog.get(\"swimmingpool_val_dataset\"), 3):\n",
    "    print(d[\"file_name\"])\n",
    "    img = cv2.imread(d[\"file_name\"])  \n",
    "    visualizer = Visualizer(img, metadata=MetadataCatalog.get(\"swimmingpool_val_dataset\"), scale=1.0)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XndZ7dJDFNPY"
   },
   "source": [
    "...and, finally, in the test test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "id": "1Zdyyv1RFMqa",
    "outputId": "742aefcc-6881-4e99-e4b6-58d8e11d5c17"
   },
   "outputs": [],
   "source": [
    "for d in random.sample(DatasetCatalog.get(\"swimmingpool_tst_dataset\"), 3):\n",
    "    print(d[\"file_name\"]) \n",
    "    img = cv2.imread(d[\"file_name\"])  \n",
    "    visualizer = Visualizer(img, metadata=MetadataCatalog.get(\"swimmingpool_tst_dataset\"), scale=1.0)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlqXIXXhW8dA"
   },
   "source": [
    "## Train!\n",
    "\n",
    "Now, let's fine-tune a coco-pretrained R50-FPN Mask R-CNN model on the swimmingpool dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQvhGtMmhcJN"
   },
   "outputs": [],
   "source": [
    "# cf. https://medium.com/@apofeniaco/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e\n",
    "# cf. https://towardsdatascience.com/face-detection-on-custom-dataset-with-detectron2-and-pytorch-using-python-23c17e99e162\n",
    "# cf. http://cocodataset.org/#detection-eval\n",
    "\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "import detectron2.utils.comm as comm\n",
    "\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "    \n",
    "    def _do_loss_eval(self):\n",
    "\n",
    "        #print('Entering here...')\n",
    "\n",
    "        # Copying inference_on_dataset from evaluator.py\n",
    "        total = len(self._data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "            \n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self._data_loader):            \n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        mean_loss = np.mean(losses)\n",
    "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        comm.synchronize()\n",
    "\n",
    "        return losses\n",
    "            \n",
    "    def _get_loss(self, data):\n",
    "\n",
    "        #print('Entering there...')\n",
    "\n",
    "        # How loss is calculated on train_loop \n",
    "        metrics_dict = self._model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "        \n",
    "        \n",
    "    def after_step(self):\n",
    "\n",
    "        #print('Entering overthere...')\n",
    "\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            self._do_loss_eval()\n",
    "        self.trainer.storage.put_scalars(timetest=12)\n",
    "\n",
    "\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"COCO_eval\", exist_ok=True)\n",
    "        output_folder = \"COCO_eval\"\n",
    "\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "  \n",
    "  def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1,LossEvalHook(\n",
    "            cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg,True)\n",
    "            )\n",
    "        ))\n",
    "        return hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n04JgOdICPb5"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = 'runs' \n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "! rm -rf {LOG_DIR}/run*\n",
    "\n",
    "runs = [] #[1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7unkuuiqLdqd"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "\n",
    "# cf. https://detectron2.readthedocs.io/modules/config.html#config-references\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"swimmingpool_trn_dataset\",)\n",
    "cfg.DATASETS.TEST = (\"swimmingpool_val_dataset\", ) #No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
    "cfg.TEST.EVAL_PERIOD = 200\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2 # Number of images processed in one iteration\n",
    "cfg.SOLVER.BASE_LR = 0.005 # 0.000025 #*5  # pick a good LR\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 1000  # Save\n",
    "cfg.SOLVER.STEPS = (2000,2500,3000,3500,4000,4500,5000,5500,6000,6500,7000,7500,8000,8500,9000,9500)\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.WARMUP_ITERS = 200\n",
    "cfg.SOLVER.MAX_ITER = 1000 # it seems to be the \"sweet spot\" ;-)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 1024  # perhaps faster, to be checked (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (\"swimming pool\")\n",
    "\n",
    "# Size of the smallest side of the image during training\n",
    "#cfg.INPUT.MIN_SIZE_TRAIN = (256,) # (640, 672, 704, 736, 768, 800)\n",
    "# Maximum size of the side of the image during training\n",
    "#cfg.INPUT.MAX_SIZE_TRAIN = 256 # 1333\n",
    "# Size of the smallest side of the image during testing. Set to zero to disable resize in testing.\n",
    "#cfg.INPUT.MIN_SIZE_TEST = 0 #800\n",
    "# Maximum size of the side of the image during testing\n",
    "#cfg.INPUT.MAX_SIZE_TEST = 0 #1333\n",
    "\n",
    "cfg.INPUT.FORMAT = \"RGB\"\n",
    "\n",
    "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "cfg.MODEL.MASK_ON = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OlmPNW4-5cd",
    "outputId": "b2854cab-df98-4605-a406-23702c95edec"
   },
   "outputs": [],
   "source": [
    "cfg.INPUT.CROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ygS8SnMh2iW"
   },
   "outputs": [],
   "source": [
    "resume=False # TO DO: make resume work!\n",
    "\n",
    "if not resume:\n",
    "  # create a new run  \n",
    "  runs.append(len(runs))\n",
    "\n",
    "  cfg.OUTPUT_DIR = os.path.join(LOG_DIR, f'run{len(runs)}')\n",
    "  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "  filelist = [ f for f in os.listdir(cfg.OUTPUT_DIR) ] #if f.endswith(\".bak\") ]\n",
    "  for f in filelist:\n",
    "    os.remove(os.path.join(cfg.OUTPUT_DIR, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gcWhcpnqdTUQ",
    "outputId": "9942c007-4bb0-48fc-f51b-f55a290e0cf8"
   },
   "outputs": [],
   "source": [
    "cfg.OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yR8hRAfCZjG4",
    "outputId": "c0eba7de-e692-4c7f-a73a-264431d06a96"
   },
   "outputs": [],
   "source": [
    "#trainer = DefaultTrainer(cfg)\n",
    "import torch\n",
    "import torchvision\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=resume)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZ9MB-ra_zec",
    "outputId": "2a2db209-47d3-4f01-bd6c-a68f91ccd620"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(cfg.OUTPUT_DIR, 'cfg.yaml'), 'w') as fp:\n",
    "  fp.write(cfg.dump())\n",
    "\n",
    "! rm {cfg.OUTPUT_DIR}/model.tar.gz\n",
    "! tar -czvf {cfg.OUTPUT_DIR}/model.tar.gz {cfg.OUTPUT_DIR}/model_final.pth {cfg.OUTPUT_DIR}/metrics.json {cfg.OUTPUT_DIR}/cfg.yaml\n",
    "! cp {cfg.OUTPUT_DIR}/model.tar.gz ../../SwimmingPoolDetection_NE/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yer88xSAYi8F",
    "outputId": "6ec910f0-e8e5-4f7a-b83a-50cf2d7c8fa8"
   },
   "outputs": [],
   "source": [
    "from detectron2.modeling import build_model\n",
    "model = build_model(cfg)\n",
    "\n",
    "def count_parameters(model, trainable_only=False):\n",
    "\n",
    "  if trainable_only:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "  else:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "print(f'{count_parameters(model, trainable_only=False)} parameters in this model, {count_parameters(model, trainable_only=True)} of which are trainable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TziQi6oZJ5nZ"
   },
   "outputs": [],
   "source": [
    "#! cp {cfg.OUTPUT_DIR}/model_final.pth /content/drive/My\\ Drive/DeepLearning/SwimmingPoolDetection_NE/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e4vdDIOXyxF"
   },
   "source": [
    "## Inference & evaluation using the trained model\n",
    "Now, let's run inference with the trained model on the validation dataset. First, let's create a predictor using the model we just trained:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "A3No2h0IZqNo",
    "outputId": "703beab5-551c-4d80-96d8-1436070bc11d"
   },
   "outputs": [],
   "source": [
    "cfg.OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKKB50QyxT_d",
    "outputId": "59a10811-dbbd-44d0-e158-b4fae0431911"
   },
   "outputs": [],
   "source": [
    "! ls {cfg.OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ya5nEuMELeq8",
    "outputId": "efd97e58-8ced-4ae9-d049-0de5d91f2f72"
   },
   "outputs": [],
   "source": [
    "! cp ../../SwimmingPoolDetection_NE/1/model.tar.gz .\n",
    "! tar xzfv model.tar.gz \n",
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9qDbk4leq1h"
   },
   "outputs": [],
   "source": [
    "# >>> this allows us to load a previously trained model <<<\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 # set the testing threshold for this model, cf. https://detectron2.readthedocs.io/modules/config.html#config-references\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWq1XHfDWiXO"
   },
   "source": [
    "Then, we randomly select several samples to visualize the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U5LhISJqWXgM",
    "outputId": "59ffd7eb-d17e-43d4-e4a8-9e0cc81bd8b1"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "for d in random.sample(DatasetCatalog.get(\"swimmingpool_tst_dataset\"), 10):\n",
    "#for d in DatasetCatalog.get(\"swimmingpool_tst_dataset\")[10:18]:   \n",
    "    print(d[\"file_name\"])\n",
    "    output_filename = \"pred_\" + d[\"file_name\"].split('/')[-1]\n",
    "    output_filename = output_filename.replace('tif', 'png')\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1], # [:, :, ::-1] is for RGB -> BGR conversion, cf. https://stackoverflow.com/questions/14556545/why-opencv-using-bgr-colour-space-instead-of-rgb\n",
    "                   metadata=MetadataCatalog.get(\"swimmingpool_tst_dataset\"), \n",
    "                   scale=1.0#, \n",
    "                   #instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    #print(dir(v))\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.imshow(v.get_image()[:, :, :])\n",
    "    cv2.imwrite(output_filename, v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2SkDGDPlV3Z"
   },
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "def _preprocess(preds):\n",
    "  \n",
    "  fields = preds['instances'].get_fields()\n",
    "\n",
    "  out = {}\n",
    "\n",
    "  # pred_boxes\n",
    "  if 'pred_boxes' in fields.keys():\n",
    "    out['pred_boxes'] = [box.cpu().numpy() for box in fields['pred_boxes']]\n",
    "  # pred_classes\n",
    "  if 'pred_classes' in fields.keys():\n",
    "    out['pred_classes'] = fields['pred_classes'].cpu().numpy()\n",
    "  # pred_masks\n",
    "  if 'pred_masks' in fields.keys():\n",
    "    out['pred_masks'] = fields['pred_masks'].cpu().numpy()\n",
    "  # scores\n",
    "  if 'scores' in fields.keys():\n",
    "    out['scores'] = fields['scores'].cpu().numpy()\n",
    "\n",
    "  return out\n",
    "\n",
    "\n",
    "def dt2predictions_to_list(preds):\n",
    "\n",
    "  instances = []\n",
    "  \n",
    "  tmp = _preprocess(preds)\n",
    "\n",
    "  for idx in range(len(tmp['scores'])):\n",
    "    instance = {}\n",
    "    instance['score'] = tmp['scores'][idx]\n",
    "    instance['pred_class'] = tmp['pred_classes'][idx]\n",
    "\n",
    "    if 'pred_masks' in tmp.keys():\n",
    "      instance['pred_mask'] = tmp['pred_masks'][idx]\n",
    "    \n",
    "    instance['pred_box'] = tmp['pred_boxes'][idx]\n",
    "    \n",
    "    instances.append(instance)\n",
    "\n",
    "  return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yqir75Q6_rAx",
    "outputId": "5f9b560a-1cba-42e1-a6bf-4de19002ae7b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Let's make predictions over the entire test set - at fixed TEST THRESHOLD\n",
    "\n",
    "OUTPUT_IMG_DIR = \"predictions-256\"\n",
    "os.makedirs(OUTPUT_IMG_DIR, exist_ok=True)\n",
    "\n",
    "predictions_dict = {}\n",
    "\n",
    "# remove already existing files\n",
    "filelist = [ f for f in os.listdir(OUTPUT_IMG_DIR) ] #if f.endswith(\".bak\") ]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(OUTPUT_IMG_DIR, f))\n",
    "\n",
    "#for d in random.sample(DatasetCatalog.get(\"swimmingpool_val_dataset\"), 3):\n",
    "for d in DatasetCatalog.get(\"swimmingpool_tst_dataset\"):\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    predictions_dict[d['file_name']] = dt2predictions_to_list(outputs)\n",
    "    \n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"swimmingpool_tst_dataset\"), \n",
    "                   scale=1.0#, \n",
    "                   #instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    \n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    #cv2_imshow(v.get_image())\n",
    "    \n",
    "    output_filename = os.path.join(OUTPUT_IMG_DIR, d['file_name'].split('/')[-1])\n",
    "    cv2.imwrite(output_filename, v.get_image()[:, :, ::-1])\n",
    "\n",
    "\n",
    "with open(f'predictions_at_fixed_threshold_dict.pkl', 'wb') as fp:\n",
    "  pickle.dump(predictions_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afBOCsjsMjQr",
    "outputId": "cbc72970-6b1c-441a-ea1b-d24f499126d8"
   },
   "outputs": [],
   "source": [
    "! rm predictions-256.tar.gz\n",
    "! tar -czvf predictions-256.tar.gz predictions-256/ > /dev/null\n",
    "! cp predictions-256.tar.gz ../../SwimmingPoolDetection_NE/1\n",
    "\n",
    "! cp predictions_at_fixed_threshold_dict.pkl ../../SwimmingPoolDetection_NE/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kblA1IyFvWbT"
   },
   "source": [
    "We can evaluate its performance using the AP metric implemented in COCO API.\n",
    "\n",
    "cf. https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9tECBQCvMv3",
    "outputId": "d2e2d21d-a4db-448b-95f4-89cdb2b2c6d7"
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# the following evaluation DOES depend on the SCORE_THRESH_TEST\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05\n",
    "\n",
    "evaluator = COCOEvaluator(\"swimmingpool_tst_dataset\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"swimmingpool_tst_dataset\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "# another equivalent way is to use trainer.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wx0lcLk8i4UW",
    "outputId": "b2672752-84eb-4bdd-810f-916eb3396ddc"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# predictions as a function of the THRESHOLD\n",
    "# N.B.: the following is not actually needed, as predictions @ any threshold can be obtained \n",
    "#       from the predictions @ threshold = 0.05 by filtering on the score \n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# predictions_at_various_thresholds = {}\n",
    "\n",
    "# for el in tqdm(np.arange(0.05, 1., 0.05)):\n",
    "#   threshold = round(float(el),2)\n",
    "#   print(f'threshold={threshold}')\n",
    "#   cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold   # set the testing threshold for this model\n",
    "#   predictor = DefaultPredictor(cfg)\n",
    "\n",
    "#   predictions_at_various_thresholds[threshold] = {}\n",
    "\n",
    "#   for d in DatasetCatalog.get(\"swimmingpool_val_dataset\"):\n",
    "#       im = cv2.imread(d[\"file_name\"])\n",
    "#       outputs = predictor(im)  \n",
    "#       predictions_at_various_thresholds[threshold][d['file_name']] = dt2predictions_to_list(outputs)\n",
    "\n",
    "# with open('predictions_at_various_thresholds_dict.pkl', 'wb') as fp:\n",
    "#   pickle.dump(predictions_at_various_thresholds, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RasEEvu6VpEu",
    "outputId": "e714b9d4-cb72-4ff6-d354-d12cf7203abf"
   },
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "threshold_str = str( round(threshold, 2) ).replace('.', 'dot')\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "trn_predictions = {}\n",
    "val_predictions = {}\n",
    "tst_predictions = {}\n",
    "\n",
    "for d in DatasetCatalog.get(\"swimmingpool_trn_dataset\"):\n",
    "  im = cv2.imread(d[\"file_name\"])\n",
    "  outputs = predictor(im)  \n",
    "  trn_predictions[d['file_name']] = dt2predictions_to_list(outputs)\n",
    "\n",
    "with open(f'trn_predictions_at_{threshold_str}_threshold.pkl', 'wb') as fp:\n",
    "  pickle.dump(trn_predictions, fp)\n",
    "\n",
    "del trn_predictions\n",
    "\n",
    "for d in DatasetCatalog.get(\"swimmingpool_val_dataset\"):\n",
    "  im = cv2.imread(d[\"file_name\"])\n",
    "  outputs = predictor(im)  \n",
    "  val_predictions[d['file_name']] = dt2predictions_to_list(outputs)\n",
    "\n",
    "with open(f'val_predictions_at_{threshold_str}_threshold.pkl', 'wb') as fp:\n",
    "  pickle.dump(val_predictions, fp)\n",
    "\n",
    "del val_predictions\n",
    "\n",
    "for d in DatasetCatalog.get(\"swimmingpool_tst_dataset\"):\n",
    "  im = cv2.imread(d[\"file_name\"])\n",
    "  outputs = predictor(im)  \n",
    "  tst_predictions[d['file_name']] = dt2predictions_to_list(outputs)\n",
    "\n",
    "with open(f'tst_predictions_at_{threshold_str}_threshold.pkl', 'wb') as fp:\n",
    "  pickle.dump(tst_predictions, fp)\n",
    "\n",
    "del tst_predictions\n",
    "\n",
    "print(\"...done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nzgGe0qkkmi"
   },
   "outputs": [],
   "source": [
    "! cp ???_predictions_at_{threshold_str}_threshold.pkl ../../SwimmingPoolDetection_NE/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ozri0ZZypCYP",
    "outputId": "a68d49c2-704a-4e21-f5e7-a0cf1dc3c8dc"
   },
   "outputs": [],
   "source": [
    "! ls ../../SwimmingPoolDetection_NE/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KlTbkw1J7c6"
   },
   "source": [
    "## Making predictions over the entire tile set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "id": "SaE67SlLl26_",
    "outputId": "9b474745-fea5-4b47-e32f-61dc7441ca1f"
   },
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDsXfz2wKCZh"
   },
   "outputs": [],
   "source": [
    "#! rm -rf all-images-256 && tar xfvz /content/drive/My\\ Drive/DeepLearning/SwimmingPoolDetection_NE/1/all-images-256.tar.gz > /dev/null\n",
    "! rm -rf all-images-256 && cp /content/drive/My\\ Drive/DeepLearning/SwimmingPoolDetection_NE/1/all-images-256.tar.gz . && tar xfvz all-images-256.tar.gz > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CVNQnQn_UOK"
   },
   "outputs": [],
   "source": [
    "! ls all-images-256 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vWBci8ekOPgy"
   },
   "outputs": [],
   "source": [
    "# the file all-images-256/18_135968_92299.tif was once found to be corrupted\n",
    "# before launching the following code block, make sure that there is no TIF file smaller than 100k\n",
    "! find all-images-256/*.tif -type f -size -100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUZY26fWO9Sx"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "threshold = 0.05\n",
    "threshold_str = str( round(threshold, 2) ).replace('.', 'dot')\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "all_predictions = {}\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "img_files = [x for x in os.listdir(\"all-images-256\") if \".tif\" in x]\n",
    "\n",
    "for file_name in tqdm(img_files):\n",
    "\n",
    "  im = cv2.imread(\"all-images-256/\" + file_name)\n",
    "  outputs = predictor(im)  \n",
    "  all_predictions[\"all-images-256/\" + file_name] = dt2predictions_to_list(outputs)\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "with open(f'all_predictions_at_{threshold_str}_threshold.pkl', 'wb') as fp:\n",
    "  pickle.dump(all_predictions, fp)\n",
    "\n",
    "del all_predictions\n",
    "\n",
    "print(f\"...done in {(toc-tic)/60} min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4klWw9yMjh5"
   },
   "outputs": [],
   "source": [
    "! cp all_predictions_at_{threshold_str}_threshold.pkl ../../SwimmingPoolDetection_NE/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLh3MflhM2CV"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "for i in tqdm(range(10)):\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Swimming Pool Detection NE - I.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "DeepLearning2",
   "language": "python",
   "name": "deeplearning2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
